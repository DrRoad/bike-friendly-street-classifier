{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 682 Project Notebook\n",
    "### Project Title: Friendly Streets: A Street Classifier for Cautious Cyclists\n",
    "### Authors: Josh Sennett, Evan Rourke\n",
    "### Fall 2018 - Professor Erik Learned-Miller\n",
    "\n",
    "This notebook is to be used as a central location to write code for the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Intialize the scenario\n",
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imresize as imresize\n",
    "from imageio import imread\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random as rdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image Labels for Places 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels():\n",
    "    # prepare all the labels\n",
    "    # scene category relevant\n",
    "    file_name_category = 'categories_places365.txt'\n",
    "    # if not os.access(file_name_category, os.W_OK):\n",
    "    #     synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "    #     os.system('wget ' + synset_url)\n",
    "    classes = list()\n",
    "    with open(file_name_category) as class_file:\n",
    "        for line in class_file:\n",
    "            classes.append(line.strip().split(' ')[0][3:])\n",
    "    classes = tuple(classes)\n",
    "\n",
    "    # indoor and outdoor relevant\n",
    "    file_name_IO = 'IO_places365.txt'\n",
    "    # if not os.access(file_name_IO, os.W_OK):\n",
    "    #     synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/IO_places365.txt'\n",
    "    #     os.system('wget ' + synset_url)\n",
    "    with open(file_name_IO) as f:\n",
    "        lines = f.readlines()\n",
    "        labels_IO = []\n",
    "        for line in lines:\n",
    "            items = line.rstrip().split()\n",
    "            labels_IO.append(int(items[-1]) -1) # 0 is indoor, 1 is outdoor\n",
    "    labels_IO = np.array(labels_IO)\n",
    "\n",
    "    # scene attribute relevant\n",
    "    file_name_attribute = 'labels_sunattribute.txt'\n",
    "    # if not os.access(file_name_attribute, os.W_OK):\n",
    "    #     synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/labels_sunattribute.txt'\n",
    "    #     os.system('wget ' + synset_url)\n",
    "    with open(file_name_attribute) as f:\n",
    "        lines = f.readlines()\n",
    "        labels_attribute = [item.rstrip() for item in lines]\n",
    "    file_name_W = 'W_sceneattribute_wideresnet18.npy'\n",
    "    # if not os.access(file_name_W, os.W_OK):\n",
    "    #     synset_url = 'http://places2.csail.mit.edu/models_places365/W_sceneattribute_wideresnet18.npy'\n",
    "    #     os.system('wget ' + synset_url)\n",
    "    W_attribute = np.load(file_name_W)\n",
    "\n",
    "    return classes, labels_IO, labels_attribute, W_attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(np.squeeze(output.data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform to CAM\n",
    "\n",
    "This function returns the Class Activation Map (CAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(imresize(cam_img, size_upsample))\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTF():\n",
    "# load the image transformer\n",
    "    tf = trn.Compose([\n",
    "        trn.Resize((224,224)),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # this model has a last conv feature map as 14x14\n",
    "\n",
    "    model_file = 'wideresnet18_places365.pth.tar'\n",
    "    # if not os.access(model_file, os.W_OK):\n",
    "    #     os.system('wget http://places2.csail.mit.edu/models_places365/' + model_file)\n",
    "    #     os.system('wget https://raw.githubusercontent.com/csailvision/places365/master/wideresnet.py')\n",
    "\n",
    "    import wideresnet\n",
    "    model = wideresnet.resnet18(num_classes=365)\n",
    "    checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "    state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "\n",
    "    # the following is deprecated, everything is migrated to python36\n",
    "\n",
    "    ## if you encounter the UnicodeDecodeError when use python3 to load the model, add the following line will fix it. Thanks to @soravux\n",
    "    #from functools import partial\n",
    "    #import pickle\n",
    "    #pickle.load = partial(pickle.load, encoding=\"latin1\")\n",
    "    #pickle.Unpickler = partial(pickle.Unpickler, encoding=\"latin1\")\n",
    "    #model = torch.load(model_file, map_location=lambda storage, loc: storage, pickle_module=pickle)\n",
    "\n",
    "    model.eval()\n",
    "    # hook the feature extractor\n",
    "    features_names = ['layer4','avgpool'] # this is the last conv layer of the resnet\n",
    "    for name in features_names:\n",
    "        model._modules.get(name).register_forward_hook(hook_feature)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a bunch of stuff and define a random image loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {'0': 'Not Bike Friendly',\n",
    "     '1': 'Bike Friendly'\n",
    "    }\n",
    "\n",
    "datadir = '../data/images/'\n",
    "camdir = '../cam/'\n",
    "testdir = datadir + 'test/'\n",
    "traindir = datadir + 'train/'\n",
    "\n",
    "def load_random_image():\n",
    "    # load a random classifier, either bike friendly or not bike friendly\n",
    "    y = rdm.choice(list(c.keys()))\n",
    "    \n",
    "    items = os.listdir(traindir + y)\n",
    "    \n",
    "    imgname = rdm.choice(items)\n",
    "    imgdir = traindir + y + '/' + imgname\n",
    "    \n",
    "    img = Image.open(imgdir)\n",
    "#     print(imgdir)\n",
    "#     print(img)\n",
    "    return img, y, imgname\n",
    "\n",
    "# image, _, _ = load_random_image()\n",
    "# plt.figure(figsize=(6,6))\n",
    "# plt.imshow(image)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following is used to generate a bunch of Class Activation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evan_rourke_er/.conda/envs/cs682/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to ../cam/0/w392696868_n4829697984_cam.jpg\n",
      "Writing to ../cam/1/w193816728_n2043277804_cam.jpg\n",
      "Writing to ../cam/1/w261756364_n5172284377_cam.jpg\n",
      "Writing to ../cam/1/w126301280_n40465534_cam.jpg\n",
      "Writing to ../cam/0/w428017300_n3672285804_cam.jpg\n",
      "Writing to ../cam/0/w165327264_n4218467368_cam.jpg\n",
      "Writing to ../cam/0/w533092481_n244284888_cam.jpg\n",
      "Writing to ../cam/0/w5534532_n1395454704_cam.jpg\n",
      "Writing to ../cam/1/w335460685_n133096015_cam.jpg\n",
      "Writing to ../cam/1/w28714075_n5589623230_cam.jpg\n"
     ]
    }
   ],
   "source": [
    "# input_images \n",
    "images = []\n",
    "img_classes = []\n",
    "img_names = []\n",
    "\n",
    "\n",
    "# Perform CAM on N number of images\n",
    "N = 10\n",
    "\n",
    "\n",
    "# Load 10 random images\n",
    "for i in range(N):\n",
    "    loaded_image, y, img_name = load_random_image()\n",
    "    img_name = img_name[:-4]\n",
    "    images.append(loaded_image)\n",
    "    img_names.append(img_name)\n",
    "    img_classes.append(y)\n",
    "        \n",
    "for j in range(len(images)):\n",
    "    # load the labels\n",
    "    classes, labels_IO, labels_attribute, W_attribute = load_labels()\n",
    "\n",
    "    # load the model\n",
    "    features_blobs = []\n",
    "    model = load_model()\n",
    "\n",
    "    # load the transformer\n",
    "    tf = returnTF() # image transformer\n",
    "\n",
    "    # get the softmax weight\n",
    "    params = list(model.parameters())\n",
    "    weight_softmax = params[-2].data.numpy()\n",
    "    weight_softmax[weight_softmax<0] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(img_names[j])\n",
    "    img = images[j]\n",
    "    input_img = V(tf(img).unsqueeze(0))\n",
    "    \n",
    "    # forward pass\n",
    "    logit = model.forward(input_img)\n",
    "    h_x = F.softmax(logit, 1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    probs = probs.numpy()\n",
    "    idx = idx.numpy()\n",
    "    \n",
    "    # save the indoor/outdoor prediction\n",
    "    io_image = np.mean(labels_IO[idx[:10]]) # vote for the indoor or outdoor\n",
    "    indoorOrOutdoor = []\n",
    "    if io_image < 0.5:\n",
    "        indoorOrOutdoor.append('--TYPE OF ENVIRONMENT: indoor')\n",
    "    else:\n",
    "        indoorOrOutdoor.append('--TYPE OF ENVIRONMENT: outdoor')\n",
    "        \n",
    "\n",
    "    # save the prediction of scene category\n",
    "    sceneCategories = []\n",
    "    sceneCategories.append('--SCENE CATEGORIES:')\n",
    "    for k in range(0, 5):\n",
    "        sceneCategories.append('{:.3f} -> {}'.format(probs[k], classes[idx[k]]))\n",
    "\n",
    "    # save the scene attributes\n",
    "    responses_attribute = W_attribute.dot(features_blobs[1])\n",
    "    idx_a = np.argsort(responses_attribute)\n",
    "    sceneAttributes = []\n",
    "    sceneAttributes.append('--SCENE ATTRIBUTES:')\n",
    "    for k in range(-1,-10,-1):\n",
    "        sceneAttributes.append('{}'.format(labels_attribute[idx_a[k]]))\n",
    "\n",
    "\n",
    "    # generate class activation mapping\n",
    "    CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
    "\n",
    "    \n",
    "    # Set the directory of where to read the images\n",
    "    imgdir = '../data/images/train/' + img_classes[j] + '/' + img_names[j] + '.jpg'\n",
    "    \n",
    "    # read the image with cv2\n",
    "    img = cv2.imread(imgdir)\n",
    "    height, width, _ = img.shape\n",
    "    heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
    "\n",
    "    heatmap_brightness = 0.4\n",
    "    image_brightness = 0.5\n",
    "    \n",
    "    # Generate heat map\n",
    "    result = (heatmap * heatmap_brightness) + (img * image_brightness)\n",
    "    \n",
    "    # Write the heatmap and original image to the cam directory\n",
    "    print(\"Writing to\", camdir + img_classes[j] + '/' + img_names[j] + '_cam.jpg')\n",
    "    cv2.imwrite(camdir + img_classes[j] + '/' + img_names[j] + '_cam.jpg', result)\n",
    "    cv2.imwrite(camdir + img_classes[j] + '/' + img_names[j] + '.jpg', img)\n",
    "\n",
    "    # Write all of the attributes to the cam directory as well\n",
    "    with open(camdir + img_classes[j] + '/' + img_names[j] + '.txt', 'w') as f:\n",
    "        for item1 in indoorOrOutdoor:\n",
    "            f.write(\"%s\\n\" %item1)\n",
    "        f.write(\"\\n\")\n",
    "        for item2 in sceneCategories:\n",
    "            f.write(\"%s\\n\" %item2)\n",
    "        f.write(\"\\n\")\n",
    "        for item3 in sceneAttributes:\n",
    "            f.write(\"%s\\n\" %item3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
